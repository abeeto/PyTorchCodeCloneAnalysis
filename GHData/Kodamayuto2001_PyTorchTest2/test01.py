#å‚è€ƒæ–‡çŒ®
#https://www.kikagaku.ai/tutorial/basic_of_computer_vision/learn/pytorch_convolution

"""
import torch,torchvisionã®ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•
ã“ã®PCã«ã¯ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒœãƒ¼ãƒ‰ãŒå…¥ã£ã¦ã„ãªã„ã®ã§,CPUã®PyTorchã‚’ä½¿ã†
conda install pytorch-cpu torchvision-cpu -c pytorch
"""
import torch
import torchvision#MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

from torchvision import transforms#Pytorchã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰å½¢ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
#print(torch.__version__)
#print(torchvision.__version__)

import numpy as np 

"""
import matplotlibã®ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•
conda install -c anaconda matplotlib
"""
import matplotlib.pyplot as plt
import matplotlib

"""
import cv2 ã®ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•
conda install -c conda-forge opencv
"""
#ç”»åƒå‡ºåŠ›ã§ä½¿ã†
#import cv2

"""
å¤šåˆ†ä½¿ã†ã‹ãªã¨æ€ã£ãŸ
"""
from PIL import Image

import torch.nn as nn
import torch.nn.functional as F
#torch.nn == ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½œã‚‹ãŸã‚ã«å¿…è¦
#torch.nn.functional == ç•³ã¿è¾¼ã¿é–¢æ•°

#ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ™‚ã®å‡¦ç†
#PyTorchã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’torch.Tensorå‹ã«ã—ã¦æ‰±ã†
#PyTorchå…¬å¼
#https://pytorch.org/docs/stable/torchvision/transforms.html
transform = transforms.Compose([transforms.ToTensor()])


#torchvision.datasetsã«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã„ãã¤ã‚‚ã‚ã‚‹
#PyTorchå…¬å¼
#https://pytorch.org/docs/stable/torchvision/datasets.html
#å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿
train = torchvision.datasets.MNIST(root="Resources/",train=True,download=True,transform=transform)

#ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­èº«ã‚’ç¢ºèª
print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­èº«\n{}".format(train))

#ã‚µãƒ³ãƒ—ãƒ«æ•°
print("ã‚µãƒ³ãƒ—ãƒ«æ•°:{}".format(len(train)))

#å…¥åŠ›å€¤ã¨ç›®æ¨™å€¤ã‚’ã‚¿ãƒ—ãƒ«ã§æ ¼ç´
print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¿ã‚¤ãƒ—ï¼š{}".format(type(train[0])))

#å…¥åŠ›å€¤
print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­èº«(æ•°å­—)ï¼š{}".format(train[0][0]))

#ç›®æ¨™å€¤ï¼ï¼ãƒ©ãƒ™ãƒ«
print("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ©ãƒ™ãƒ«:{}".format(train[0][1]))

#å…¥åŠ›å€¤ã®ã‚µã‚¤ã‚º
print("å…¥åŠ›å€¤ã®ã‚µã‚¤ã‚º{}".format(train[0][0].shape))

#PyTorchã®ç‰¹æ€§ç¢ºèª
#PyTorchã§ã¯(channels,height,width)ã®é †ã«æ ¼ç´ã€€â€»"(height,width,channels)"ã§ã¯ãªã„
#ç¢ºèª
c,h,w = train[0][0].shape

print("channels={}".format(c))
print("height  ={}".format(h))
print("width   ={}".format(w))

#ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­èº«ã‚’æ•°å­—ã§ã¯ãªãç”»åƒã§ç¢ºèªã—ãŸã„
#Matplotlibã‚’ä½¿ã†
#train[0][0]ã®ãƒ‡ãƒ¼ã‚¿æ ¼ç´é †ç•ªã‚’å¤‰æ›´
# (0:channels, 1:height, 2:width) -> (1:height, 2:widthã€0:channels)
img = np.transpose(train[0][0],(1,2,0))
#ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã¤ã¾ã‚Šç™½é»’ç”»åƒã§è¡¨ç¤º
#ãƒãƒ£ãƒãƒ«ã‚µã‚¤ã‚ºã¯ãªãã™
img = img.reshape(img.shape[0],img.shape[1])
print("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”¨ãƒãƒ£ãƒãƒ«æ’é™¤çµæœï¼š{}".format(img.shape))
print("ãƒãƒ£ãƒãƒ«ï¼š{}".format(c))


plt.imshow(img,cmap="gray")
#è¡¨ç¤º
plt.show()

#---------------ä¸€é€£ã®æµã‚Œã®ç¢ºèª---------------
#ç‰¹å¾´é‡æŠ½å‡º
#--ç•³ã¿è¾¼ã¿
#--ãƒ—ãƒ¼ãƒªãƒ³ã‚°
#--å…¨çµåˆå±¤
x = train[0][0]
print(x.shape)

print("-------------------------------------------------------------------------")

#ç•³ã¿è¾¼ã¿å±¤ã®å®šç¾©
#ç”¨èªè§£èª¬
#https://qiita.com/mathlive/items/8e1f9a8467fff8dfd03c
#https://torch.classcat.com/2017/04/14/pytorch-tutorial-neural-networks/
#https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html
#PyTorchå…¬å¼
#https://pytorch.org/docs/master/generated/torch.nn.Conv2d.html
conv = nn.Conv2d(in_channels=1,out_channels=4,kernel_size=3,stride=1,padding=1)
"""
in_channels (int)               â€“å…¥åŠ›ç”»åƒã®ãƒãƒ£ãƒãƒ«æ•°
out_channels (int)              â€“ãŸãŸã¿è¾¼ã¿ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒãƒ«ã®æ•°
kernel_size (int or tuple)      â€“ ãŸãŸã¿è¾¼ã¿ã‚«ãƒ¼ãƒãƒ«ã®ã‚µã‚¤ã‚º
stride (int or tuple, optional) â€“ç•³ã¿è¾¼ã¿ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š1
padding (int or tuple, optional)â€“å…¥åŠ›ã®ä¸¡å´ã«è¿½åŠ ã•ã‚Œã‚‹ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š0
padding_mode (string, optional) - 'zeros' ã¾ãŸã¯ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š'reflect''replicate''circular''zeros'
dilation(int or tuple, optional)â€“ã‚«ãƒ¼ãƒãƒ«è¦ç´ é–“ã®é–“éš”ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š1
groups (int, optional)          â€“å…¥åŠ›ãƒãƒ£ãƒãƒ«ã‹ã‚‰å‡ºåŠ›ãƒãƒ£ãƒãƒ«ã¸ã®ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸæ¥ç¶šã®æ•°ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š1
bias (bool, optional)           â€“ã®å ´åˆTrueã€å­¦ç¿’å¯èƒ½ãªãƒã‚¤ã‚¢ã‚¹ã‚’å‡ºåŠ›ã«è¿½åŠ ã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šTrue
"""
#ç•³ã¿è¾¼ã¿å±¤ã‚’å®£è¨€ã—ãŸæ™‚ç‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿ã®é‡ã¿ãŒãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚ŠæŒ¯ã‚‰ã‚Œã¦ã„ã‚‹
print("conv.weight=\n{}".format(conv.weight))
print("conv.weight.shape=\n{}".format(conv.weight.shape))
print("conv.bias=\n{}".format(conv.bias))
print("conv.bias.shape=\n{}".format(conv.bias.shape))

#(batchsize,channels,height,width)
#å…¥åŠ›å±¤
x = x.reshape(1,1,28,28)
#ğŸ‘‡
#ç•³ã¿è¾¼ã¿å±¤
x = conv(x)
print("ç•³ã¿ã“ã¾ã‚ŒãŸã‚‚ã®ï¼š\n{}".format(x))
print(x.shape)
#ğŸ‘‡
#ãƒ—ãƒ¼ãƒªãƒ³ã‚°å‡¦ç†
x = F.max_pool2d(x,kernel_size=2,stride=2)
print(x.shape)
#ğŸ‘‡
#ç•³ã¿è¾¼ã¿å±¤
#ğŸ‘‡
#ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤
#ğŸ‘‡
#ç•³ã¿è¾¼ã¿å±¤
#ğŸ‘‡
#ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤
#ğŸ‘‡
#ç•³ã¿è¾¼ã¿å±¤
#ğŸ‘‡
#å…¨çµåˆå±¤

#å…¨çµåˆå±¤ã¨çµåˆ
print("-------------------------------------------------------------------------")
print("channels:{}".format(x.shape[1]))
print("heights :{}".format(x.shape[2]))
print("width   :{}".format(x.shape[3]))
#Flatten 
#4éšã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’1éšã®ãƒ†ãƒ³ã‚½ãƒ«(ãƒ™ã‚¯ãƒˆãƒ«)ã«å¤‰æ›
x_shape = x.shape[1] * x.shape[2] * x.shape[3]
print("x_shape :{}".format(x_shape))

# ä»Šå›ã¯ãƒ™ã‚¯ãƒˆãƒ«ã®è¦ç´ æ•°ãŒæ±ºã¾ã£ã¦ã„ã‚‹ãŸã‚ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯è‡ªå‹•ã§è¨­å®š
# -1 ã¨ã™ã‚‹ã¨ã‚‚ã†ç‰‡æ–¹ã®è¦ç´ ã«åˆã‚ã›ã¦è‡ªå‹•çš„ã«è¨­å®šã•ã‚Œã‚‹
#ã‚µã‚¤ã‚ºå¤‰æ›´ã‚’ã™ã‚‹éš›ã«ã¯ torch.view() é–¢æ•°ã‚’ä½¿ã†
x = x.view(-1, x_shape)
print("x.shape :{}".format(x.shape))

#å…¨çµåˆå±¤ã®å®šç¾© ãƒãƒ¼ãƒ‰æ•°ã‚’ 10
fc = nn.Linear(x_shape,10)#x_shape=784

#å‡ºåŠ›å±¤
#ç·šå½¢å¤‰æ›
x = fc(x)
print(x)
print(x.shape)







