# -*- coding: utf-8 -*-
"""Final-Cnn-Cifar10-resnet-reg-lec5-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_QxTfvFISBZ6kn5mMyVB0MFROXFaw16i
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import torch 
import torchvision

import torch.nn as nn 
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from torchvision.datasets import ImageFolder
from torchvision.datasets.utils import download_url
from torch.utils.data import DataLoader
import torchvision.transforms as tt 
from torch.utils.data import random_split
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
# %matplotlib inline

plt.rcParams['figure.facecolor'] = '#ffffff'

from torchvision.datasets.utils import download_and_extract_archive

    ## download mini-imagenet
url = "https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz"
filename ='Imagenet.tgz'
root = '~/tmp/'
download_and_extract_archive(url, root, filename)

data_dir = '/content/Imagenet.tgz/cifar10'
print(os.listdir(data_dir))
classes = os.listdir('/content/Imagenet.tgz/cifar10/train')
print(classes)
classes[2]

train_tfms = tt.Compose([tt.ToTensor()])
valid_tfms = tt.Compose([tt.ToTensor()])

# PyTorch datasets
train_ds = ImageFolder(data_dir + '/train',train_tfms)
valid_ds = ImageFolder(data_dir + '/test',valid_tfms)
len(valid_ds)

batch_size=104
train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(valid_ds, batch_size*2, num_workers=4, pin_memory=True)

image, label = train_ds[25000]
print(image.shape)
plt.imshow(image.permute(1, 2, 0))

print('Label:',train_ds.classes[label])

for images, _ in train_loader:
    print('images.shape:', images.shape)
    plt.figure(figsize=(16,8))
    plt.axis('off')
    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))
    break

loader=DataLoader(train_ds, batch_size=len(train_ds), shuffle=True, num_workers=4, pin_memory=True)
data=next(iter(train_loader))

mean=data[0].mean()
std=data[0].std()
mean, std

plt.hist(data[0].flatten())
plt.axvline(data[0].mean())

train_normalised = tt.Compose([tt.ToTensor(),tt.Normalize(mean,std)])
train_nz = ImageFolder(data_dir + '/train',train_normalised)

loader_normalised=DataLoader(train_nz, batch_size=len(train_nz),num_workers=2)
data1=next(iter(loader_normalised))

mean_normalised=data1[0].mean()
std_normalised=data1[0].std()
mean_normalised,std_normalised

plt.hist(data1[0].flatten())
plt.axvline(data1[0].mean())

train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), 
                         tt.RandomHorizontalFlip(), 
                         
                         tt.ToTensor(), 
                         tt.Normalize(mean,std)])
train_ds = ImageFolder(data_dir+'/train', train_tfms)

batch_size=104
train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(valid_ds, batch_size*2, num_workers=4, pin_memory=True)

for images, _ in train_loader:
    print('images.shape:', images.shape)
    plt.figure(figsize=(16,8))
    plt.axis('off')
    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))
    break

def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl: 
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

device = get_default_device()
device

class SimpleResidualBlock(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        out = self.conv2(out)
        return self.relu2(out) + x